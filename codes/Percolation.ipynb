{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this in Julia REPL: \n",
    "# using IJulia\n",
    "#  IJulia.installkernel(\"Julia 12 Threads\", env=Dict(\"JULIA_NUM_THREADS\" => \"12\",))\n",
    "\n",
    "using  CSV, DataFrames, Random, LinearAlgebra, Distributions, EcologicalNetworks\n",
    "\n",
    "Lx=1000 \n",
    "Ly=500\n",
    "abun=1000\n",
    "timepoints=10000\n",
    "nbirth=ndeath=convert(Int64,floor(abun*0.1))\n",
    "\n",
    "reps=1:2\n",
    "\n",
    "disp=(2,5,10,15,30)\n",
    "methodrefs=DataFrame(ind=[1, 2, 3], methods=[\"neutral\",\"positive\",\"negative\"])\n",
    "pars=collect(Iterators.product(disp,methodrefs[:,:ind]))\n",
    "\n",
    "pars=pars[[1,2]]\n",
    "\n",
    "@threads for i1 in reps\n",
    "\n",
    "cd(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\")\n",
    "\n",
    "landscape=CSV.read(string(\"landscape_\",i1,\".csv\"), DataFrame)\n",
    "      \n",
    "ind=landscape[1,2]\n",
    "rangepar=landscape[1,3]    \n",
    "    \n",
    "landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "#landscape[:,:rep]=fill(1,nrow(landscape))\n",
    "#landscape[:,:rangepars]=fill(5,nrow(landscape))\n",
    "    \n",
    "initial=filter(:pres => x-> x .== 1,landscape)\n",
    "initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "\n",
    "CSV.write(string(\"initial_\",i1,\".csv\"),initial)\n",
    "\n",
    "popmat=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "popmat=Matrix(popmat[:,Not(\"y\")])\n",
    "\n",
    "\n",
    "habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "habmat=Matrix(habmat[:,Not(\"y\")])\n",
    "\n",
    "#Threshold for a suitable habitat\n",
    "mid=quantile(landscape[:,:soiltype],0.5)\n",
    "\n",
    "\n",
    "for i2 in 1:length(pars)\n",
    "        \n",
    "        disps=pars[i2][1]\n",
    "        methods=pars[i2][2]\n",
    "        \n",
    "        #Define dispersal probability as a function of #neighbors for all three dispersal methods\n",
    "        maxnb=((2*disps+1)^2)-1\n",
    "        neigh=log.(maxnb,1:maxnb)\n",
    "        disp_list=([0;fill(1,length(neigh))],[0;0.5 .+ (neigh ./2)],[0;1.0 .- neigh])  \n",
    "\n",
    "        for i in 1:10\n",
    "\n",
    "            samp=shuffle((findall(popmat.==1)))\n",
    "            popmat[samp[1:ndeath]].=0\n",
    "\n",
    "            j=0\n",
    "\n",
    "            while j<nbirth\n",
    "\n",
    "                x=sample(1:Ly)\n",
    "                y=sample(1:Lx)\n",
    "\n",
    "                if(popmat[x,y]==0)\n",
    "\n",
    "                    xs=((x-disps):(x+disps))\n",
    "                    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "                    ys=(y-disps):(y+disps)\n",
    "                    ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "                    nb=sum(popmat[xs,ys])+1\n",
    "\n",
    "                    val=ceil(Int,habmat[x,y]-mid)*\n",
    "                        ceil(Int,(disp_list[methods][nb]-rand()))\n",
    "\n",
    "                    popmat[x,y]=val\n",
    "\n",
    "                    j=j+val\n",
    "\n",
    "                end\n",
    "            end   \n",
    "\n",
    "        end \n",
    "\n",
    "            popmat1=DataFrame(popmat,:auto)\n",
    "            rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "            popmat1[:,:y].=1:500\n",
    "            popmat1=stack(popmat1,1:1000)\n",
    "            rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "            popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "            filter!(:pres => x-> x .== 1,popmat1)\n",
    "            popmat1[:,:rep].=ind\n",
    "            popmat1[:,:rangepar].=rangepars\n",
    "            popmat1[:,:disp].=disps\n",
    "            popmat1[:,:method].=methodrefs[methods,2]\n",
    "            \n",
    "            CSV.write(string(\"popmat_\",i1,\"_\",i2,\".csv\"),popmat1)\n",
    "\n",
    "end\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling FFMPEG [c87230d0-a227-11e9-1b43-d7ebe4e7570a]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing FFMPEG [c87230d0-a227-11e9-1b43-d7ebe4e7570a].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling FFMPEG_jll [b22a6f82-2f65-5046-a5b2-351ab43fb4e5]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing FFMPEG_jll [b22a6f82-2f65-5046-a5b2-351ab43fb4e5].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling libass_jll [0ac62f75-1d6f-5e53-bd7c-93b484bb37c0]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing libass_jll [0ac62f75-1d6f-5e53-bd7c-93b484bb37c0].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling HarfBuzz_jll [2e76f6c2-a576-52d4-95c1-20adfe4de566]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing HarfBuzz_jll [2e76f6c2-a576-52d4-95c1-20adfe4de566].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe call to compilecache failed to create a usable precompiled cache file for Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a]\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception = Required dependency Fontconfig_jll [a3f928ae-7b40-5064-980b-68af3947d34b] failed to load from a cache file.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1818\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling GR [28b8d3ca-fb5f-59d9-8090-bfdbd6d07a71]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule Cairo_jll with build ID ffffffff-ffff-ffff-0000-17ff0c14d077 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1793\u001b[39m\n",
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mimport GR_jll failed.\n",
      "\u001b[91m\u001b[1m│ \u001b[22m\u001b[39mConsider using `GR.GRPreferences.use_jll_binary()` or\n",
      "\u001b[91m\u001b[1m│ \u001b[22m\u001b[39m`GR.GRPreferences.use_upstream_binary()` to repair.\n",
      "\u001b[91m\u001b[1m│ \u001b[22m\u001b[39mImporting GR a second time will allow use of these functions.\n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ GR.GRPreferences C:\\Users\\mihir\\.julia\\packages\\GR\\nDZgF\\src\\preferences.jl:8\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing GR [28b8d3ca-fb5f-59d9-8090-bfdbd6d07a71].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling GR_jll [d2c73de3-f751-5644-a686-071e5b155ba9]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule Cairo_jll with build ID ffffffff-ffff-ffff-0000-17ff0c14d077 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean Cairo_jll [83423d85-b0ee-5818-9007-b63ccbeb887a] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1793\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing GR_jll [d2c73de3-f751-5644-a686-071e5b155ba9].\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling IJuliaExt [2f4121a4-3b3a-5ce6-9c5e-1f2673ce168a]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule Plots with build ID ffffffff-ffff-ffff-0000-17fafdd6c4e1 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1793\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing IJuliaExt [2f4121a4-3b3a-5ce6-9c5e-1f2673ce168a].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_f_cm (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Functions to calculate clusters and further process the simulated data\n",
    "\n",
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances, \n",
    "CategoricalArrays, GLM, Plots, Optim\n",
    "\n",
    "\n",
    "function divisors(Lx::Int64,Ly::Int64)\n",
    "    \n",
    "    d=collect(1:min(Lx,Ly))\n",
    "    d=d[mod.(min(Lx,Ly),d) .==0]\n",
    "    \n",
    "    return sort(union(d, collect(2:2:ceil(Int64,min(Lx,Ly)/4))))\n",
    "end\n",
    "    \n",
    "\n",
    "function perc_up(dat::DataFrame,Lx::Int64,Ly::Int64)\n",
    "    \n",
    "    d=divisors(Lx,Ly)\n",
    "    \n",
    "    a=DataFrame(vec(collect(Iterators.product(1:Lx,1:Ly))))\n",
    "    \n",
    "    select!(a,\"1\"=>\"x\",\"2\"=>\"y\")\n",
    "    \n",
    "    dat=outerjoin(dat,a, on= [:x=>:x,:y=>:y],order=:right)\n",
    "    \n",
    "    replace!(dat.pres,missing=>0)\n",
    "    \n",
    "    result=DataFrame()\n",
    "    \n",
    "    for i in d\n",
    "        \n",
    "        cutx=ceil.(Int64,collect((1:Lx) ./ i))\n",
    "        cuty=ceil.(Int64,collect((1:Ly) ./ i))\n",
    "        \n",
    "        dat1=deepcopy(dat)\n",
    "        \n",
    "        dat1[!,:x1] =cutx[dat1.x]\n",
    "        dat1[!,:y1] = cuty[dat1.y]\n",
    "        \n",
    "        dat1=combine(groupby(dat1,[:x1,:y1]),:pres=>sum)\n",
    "        \n",
    "        mat1=unstack(dat1,:y1,:x1,:pres_sum)\n",
    "        \n",
    "        mat1=Matrix{Int64}(select(mat1,Not(:y1)))\n",
    "        \n",
    "        clust=zeros(Int64,size(mat1)[1],size(mat1)[2])\n",
    "        \n",
    "        largest=0\n",
    "        \n",
    "        lbl=collect(0:length(clust))\n",
    "        \n",
    "        rw=size(mat1)[1]\n",
    "        cl=size(mat1)[2]\n",
    "        \n",
    "        for i2 in 1:cl \n",
    "            for i1 in 1:rw\n",
    "                \n",
    "                if mat1[i1,i2] > 0\n",
    "                    \n",
    "                    left= (i2-1)==0 ? 0 : clust[i1,i2-1]\n",
    "                    above= (i1-1)==0 ? 0 : clust[i1-1,i2]\n",
    "                    \n",
    "                    if (left==0) && (above==0)\n",
    "                        \n",
    "                        largest+=1\n",
    "                        clust[i1,i2]=largest\n",
    "                        lbl[(rw*(i2-1))+i1]=largest\n",
    "                        \n",
    "                    else\n",
    "                        \n",
    "                        if (left!=0) && (above==0)\n",
    "                            \n",
    "                            clust[i1,i2]=clust[i1,i2-1]\n",
    "                            lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-2))+i1]\n",
    "                            \n",
    "                        else\n",
    "                            \n",
    "                            if (left==0) && (above!=0)\n",
    "                                \n",
    "                                clust[i1,i2]=clust[i1-1,i2]\n",
    "                                lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-1))+i1-1]\n",
    "                                \n",
    "                            else\n",
    "                                \n",
    "                                newlab=min(left,above)\n",
    "                                lbl[findall(x-> x==left || x==above, lbl)] .=newlab\n",
    "                                clust[i1,i2]=newlab\n",
    "                                clust[findall(x-> x==max(left,above), clust)].=newlab\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        res=DataFrame(pres=reshape(mat1,length(mat1)),cluster=reshape(clust,length(clust)))\n",
    "        res=combine(groupby(res,:cluster),:pres=>sum)\n",
    "        res=res[res.cluster .!=0,:]\n",
    "\n",
    "        freq=combine(groupby(res,:pres_sum),:pres_sum=>length)\n",
    "\n",
    "        append!(result,DataFrame(d_cutoff=i,cluster=freq.pres_sum,freq=freq.pres_sum_length)) \n",
    "        \n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end\n",
    "\n",
    "function fish(a,b)\n",
    "    \n",
    "    a=log2.(a)\n",
    "    b=log2.(b.+1)\n",
    "    \n",
    "    return coef(lm(@formula(a~b),DataFrame(a=a,b=b)))[2]\n",
    "    \n",
    "end\n",
    "    \n",
    "\n",
    "function weibull_fit(a,b)\n",
    "        \n",
    "        res=0.0\n",
    "        \n",
    "        try \n",
    "     \n",
    "            res=shape(fit_mle(Weibull,wsample(a,b,100) .+ 1))\n",
    "                \n",
    "        catch err\n",
    "            \n",
    "            if isa(error, DomainError)\n",
    "                \n",
    "                res=0.0\n",
    "                \n",
    "            end\n",
    "        end\n",
    "        \n",
    "        return res\n",
    "        \n",
    "end\n",
    "\n",
    "\n",
    "function segmented_f(dat::DataFrame,d::Vector{Int64})\n",
    "    \n",
    "    min_dev = Inf\n",
    "    best_bp = 0\n",
    "    current1=current2=nothing\n",
    "    \n",
    "    for bp in 3:(length(d)-2)\n",
    "        \n",
    "        current1=lm(@formula(f~d_cutoff),dat[1:bp,:])\n",
    "        current2=lm(@formula(f~d_cutoff),dat[(bp+1):length(d),:])\n",
    "        \n",
    "        if (deviance(current1)+deviance(current2)) < min_dev\n",
    "            \n",
    "            min_dev= deviance(current1)+deviance(current2)\n",
    "            best_bp=bp\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return dat.d_cutoff[best_bp],min_dev\n",
    "    \n",
    "end\n",
    "\n",
    "function segmented_cm(dat::DataFrame,d::Vector{Int64})\n",
    "    \n",
    "    min_dev = Inf\n",
    "    best_bp = 0\n",
    "    current1=current2=nothing\n",
    "    \n",
    "    for bp in 3:(length(d)-2)\n",
    "        \n",
    "        current1=lm(@formula(cm~d_cutoff),dat[1:bp,:])\n",
    "        current2=lm(@formula(cm~d_cutoff),dat[(bp+1):length(d),:])\n",
    "        \n",
    "        if (deviance(current1)+deviance(current2)) < min_dev\n",
    "            \n",
    "            min_dev= deviance(current1)+deviance(current2)\n",
    "            best_bp=bp\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return dat.d_cutoff[best_bp],min_dev\n",
    "    \n",
    "end\n",
    "    \n",
    "    \n",
    "function get_f_cm(dat,Lx,Ly)\n",
    "    \n",
    "    res=perc_up(dat,Lx,Ly)\n",
    "\n",
    "    a=DataFrame(vec(collect(Iterators.product(divisors(Lx,Ly),1:sum(dat.pres)))))\n",
    "\n",
    "    select!(a,\"1\"=>\"d_cutoff\",\"2\"=>\"cluster\")\n",
    "\n",
    "    res1=outerjoin(res,a, on= [:d_cutoff=>:d_cutoff,:cluster=>:cluster],order=:right)\n",
    "\n",
    "    replace!(res1.freq,missing=>0)\n",
    "    \n",
    "    res1.freq =identity.(res1.freq)\n",
    "\n",
    "    fishdat=DataFrame()\n",
    "    wshapedat=DataFrame()\n",
    "    clusmax=DataFrame()\n",
    "            \n",
    "    dv=divisors(Lx,Ly)\n",
    "            \n",
    "    clusmax=combine(groupby(res,:d_cutoff),:cluster=>maximum)\n",
    "    \n",
    "    rename!(clusmax,:cluster_maximum => :cm)\n",
    "\n",
    "    for i in 1:(length(dv)-1)\n",
    "\n",
    "        dat1=res1[res1.d_cutoff .==dv[i],:]\n",
    "                \n",
    "        wshape=append!(wshapedat,DataFrame(d_cutoff=dv[i],wshape=weibull_fit(dat1.cluster,dat1.freq)))\n",
    "\n",
    "        fishdat=append!(fishdat,DataFrame(d_cutoff=dv[i],f=fish(dat1.cluster,dat1.freq)))\n",
    "\n",
    "    end\n",
    "\n",
    "    return innerjoin(fishdat,clusmax,wshapedat,on=:d_cutoff)\n",
    "\n",
    "end\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function weibull_fit(a,b)\n",
    "        \n",
    "        res=0.0\n",
    "        \n",
    "        try \n",
    "     \n",
    "            res=shape(fit_mle(Weibull,wsample(a,b,100) .+ 1))\n",
    "                \n",
    "        catch err\n",
    "            \n",
    "            if isa(error, DomainError)\n",
    "                \n",
    "                res=0.0\n",
    "                \n",
    "            end\n",
    "        end\n",
    "        \n",
    "        return res\n",
    "        \n",
    "end\n",
    "\n",
    "function weibull2(a,b,binlength,m)\n",
    "    \n",
    "    res=0.0\n",
    "            \n",
    "        try \n",
    "        \n",
    "            x=reduce(vcat,[fill(a[x1],b[x1]) for x1 in 1:length(a)])\n",
    "            \n",
    "            l = length(x)\n",
    "\n",
    "            d,r=divrem(m,binlength)\n",
    "\n",
    "            lns=fill(binlength,d)\n",
    "            lns=vcat(lns,r)\n",
    "\n",
    "            df=DataFrame(bins=reduce(vcat, [fill(i, v) for (i, v) in enumerate(lns)]),freq=0)\n",
    "\n",
    "            df.vals = 1 .+ binlength .*(df.bins .- 1)\n",
    "\n",
    "            [df.freq[x] += 1 for x in size(df)[1]]\n",
    "\n",
    "            df=combine(groupby(df,:vals),:freq=> sum,renamecols=false)\n",
    "\n",
    "            df=df[df.freq .>0,:]\n",
    "\n",
    "            res=shape(fit_mle(Weibull,wsample(df.vals,df.freq,100)))\n",
    "                \n",
    "        catch err\n",
    "            \n",
    "            if isa(error, DomainError)\n",
    "                \n",
    "                res=0.0\n",
    "                \n",
    "            end\n",
    "        end\n",
    "        \n",
    "        return res\n",
    "end\n",
    "        \n",
    "function weibull3(a,b,binlength,m)\n",
    "    \n",
    "        \n",
    "            x=reduce(vcat,[fill(a[i],b[i]) for i in 1:length(a)])\n",
    "            \n",
    "            l = length(x)\n",
    "\n",
    "            d,r=divrem(m,binlength)\n",
    "\n",
    "            lns=fill(binlength,d)\n",
    "            lns=vcat(lns,r)\n",
    "\n",
    "            df=DataFrame(bins=reduce(vcat, [fill(i, v) for (i, v) in enumerate(lns)]),freq=0)\n",
    "\n",
    "            df.vals = 1 .+ binlength .*(df.bins .- 1)\n",
    "\n",
    "            [df.freq[x] += 1 for x in size(df)[1]]\n",
    "\n",
    "            df=combine(groupby(df,:vals),:freq=> sum,renamecols=false)\n",
    "\n",
    "            df=df[df.freq .>0,:]\n",
    "\n",
    "            res=shape(fit_mle(Weibull,wsample(df.vals,df.freq,100)))\n",
    "        \n",
    "            return res\n",
    "end\n",
    "        \n",
    "function weibull_reg(a,b)\n",
    "    \n",
    "    b1= b ./ sum(b)\n",
    "    b1= cumsum(b1)\n",
    "    b2= log.(-log.(1 .- b1))\n",
    "    a1=log.(a)\n",
    "\n",
    "    df=DataFrame(X=a1,Y=b1)\n",
    "\n",
    "    return coef(lm(@formula(Y~X),df))[2]\n",
    "end\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using EcologicalNetworksPlots\n",
    "\n",
    "N = convert(BipartiteNetwork, web_of_life(\"M_PA_003\"))\n",
    "\n",
    "n = repeat(3:12, outer=20)\n",
    "m = Array{Dict}(undef, length(n))\n",
    "\n",
    "for i in eachindex(n)\n",
    "  # Each run returns the network and its modules\n",
    "  # We discard the network, and assign the modules to our object\n",
    "  _, m[i] = n_random_modules(n[i])(N) |> x -> brim(x...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 39 entries:\n",
       "  \"Pseudomyrmex concolor\"      => 1\n",
       "  \"Cecropia purpurascens\"      => 2\n",
       "  \"Hirtella myrmecophila\"      => 2\n",
       "  \"Allomerus octoarticulatus \" => 2\n",
       "  \"Cordia nodosa\"              => 1\n",
       "  \"Azteca isthmica\"            => 2\n",
       "  \"Allomerus prancei\"          => 3\n",
       "  \"Tococa bullifera\"           => 3\n",
       "  \"Azteca schummani\"           => 1\n",
       "  \"Pourouma heterophylla\"      => 1\n",
       "  \"Crematogaster sp2 M_PA_001\" => 3\n",
       "  \"Pseudomyrmex nigrescens\"    => 1\n",
       "  \"Azteca sp1 M_PA_001\"        => 1\n",
       "  \"Azteca sp4 M_PA_001\"        => 3\n",
       "  \"Cecropia distachya\"         => 2\n",
       "  \"Tachigali polyphylla\"       => 1\n",
       "  \"Maieta guianensis\"          => 3\n",
       "  \"Azteca sp5 M_PA_001\"        => 1\n",
       "  \"Duroia saccifera\"           => 1\n",
       "  \"Amaioua guianensis\"         => 2\n",
       "  \"Cecropia concolor\"          => 2\n",
       "  \"Solenops sp1 M_PA_001\"      => 3\n",
       "  \"Azteca sp6 M_PA_001\"        => 2\n",
       "  \"Azteca sp3 M_PA_001\"        => 1\n",
       "  \"Pheidole minutula\"          => 3\n",
       "  ⋮                            => ⋮"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx=32\n",
    "Ly=32\n",
    "abun=trunc(Int,Lx*Ly*0.1)\n",
    "\n",
    "dat=DataFrame(x=sample(1:Ly,abun,replace=true),y=sample(1:Lx,abun,replace=true),pres=1)\n",
    "    \n",
    "    d=divisors(Lx,Ly)\n",
    "    \n",
    "    a=DataFrame(vec(collect(Iterators.product(1:Lx,1:Ly))))\n",
    "    \n",
    "    select!(a,\"1\"=>\"x\",\"2\"=>\"y\")\n",
    "    \n",
    "    dat=outerjoin(dat,a, on= [:x=>:x,:y=>:y],order=:right)\n",
    "    \n",
    "    replace!(dat.pres,missing=>0)\n",
    "    \n",
    "    result=DataFrame()\n",
    "    \n",
    "    i=2\n",
    "        \n",
    "        cutx=ceil.(Int64,collect((1:Lx) ./ i))\n",
    "        cuty=ceil.(Int64,collect((1:Ly) ./ i))\n",
    "        \n",
    "        dat1=deepcopy(dat)\n",
    "        \n",
    "        dat1[!,:x1] =cutx[dat1.x]\n",
    "        dat1[!,:y1] = cuty[dat1.y]\n",
    "        \n",
    "        dat1=combine(groupby(dat1,[:x1,:y1]),:pres=>sum)\n",
    "        \n",
    "        mat1=unstack(dat1,:y1,:x1,:pres_sum)\n",
    "        \n",
    "        mat1=Matrix{Int64}(select(mat1,Not(:y1)))\n",
    "        \n",
    "        clust=zeros(Int64,size(mat1)[1],size(mat1)[2])\n",
    "        \n",
    "        largest=0\n",
    "        \n",
    "        lbl=collect(0:length(clust))\n",
    "        \n",
    "        rw=size(mat1)[1]\n",
    "        cl=size(mat1)[2]\n",
    "        \n",
    "        for i2 in 1:cl \n",
    "            for i1 in 1:rw\n",
    "                \n",
    "                if mat1[i1,i2] > 0\n",
    "                    \n",
    "                    left= (i2-1)==0 ? 0 : clust[i1,i2-1]\n",
    "                    above= (i1-1)==0 ? 0 : clust[i1-1,i2]\n",
    "                    \n",
    "                    if (left==0) && (above==0)\n",
    "                        \n",
    "                        largest+=1\n",
    "                        clust[i1,i2]=largest\n",
    "                        lbl[(rw*(i2-1))+i1]=largest\n",
    "                        \n",
    "                    else\n",
    "                        \n",
    "                        if (left!=0) && (above==0)\n",
    "                            \n",
    "                            clust[i1,i2]=clust[i1,i2-1]\n",
    "                            lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-2))+i1]\n",
    "                            \n",
    "                        else\n",
    "                            \n",
    "                            if (left==0) && (above!=0)\n",
    "                                \n",
    "                                clust[i1,i2]=clust[i1-1,i2]\n",
    "                                lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-1))+i1-1]\n",
    "                                \n",
    "                            else\n",
    "                                \n",
    "                                newlab=min(left,above)\n",
    "                                lbl[findall(x-> x==left || x==above, lbl)] .=newlab\n",
    "                                clust[i1,i2]=newlab\n",
    "                                clust[findall(x-> x==max(left,above), clust)].=newlab\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "using EcologicalNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>32×3 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">7 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">cluster</th><th style = \"text-align: left;\">xc</th><th style = \"text-align: left;\">yc</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4.54545</td><td style = \"text-align: right;\">2.90909</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">1.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">13.7</td><td style = \"text-align: right;\">2.2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">3.5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">5.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">14.0</td><td style = \"text-align: right;\">5.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">6.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">12.5</td><td style = \"text-align: right;\">6.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">6.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">8.25</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">14.5</td><td style = \"text-align: right;\">8.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">9.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">9.5</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">21</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">15.0</td><td style = \"text-align: right;\">12.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">22</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">13.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">23</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">13.5</td><td style = \"text-align: right;\">13.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">24</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">14.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">25</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">15.0</td><td style = \"text-align: right;\">15.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">26</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">15.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">27</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">15.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">28</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">6.5</td><td style = \"text-align: right;\">15.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">29</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">15.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">30</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">16.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">31</td><td style = \"text-align: right;\">32</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">16.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">32</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">16.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& cluster & xc & yc\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 4.54545 & 2.90909 \\\\\n",
       "\t2 & 3 & 11.0 & 1.0 \\\\\n",
       "\t3 & 4 & 13.7 & 2.2 \\\\\n",
       "\t4 & 5 & 10.0 & 3.5 \\\\\n",
       "\t5 & 6 & 6.0 & 5.0 \\\\\n",
       "\t6 & 7 & 14.0 & 5.0 \\\\\n",
       "\t7 & 8 & 5.0 & 6.0 \\\\\n",
       "\t8 & 9 & 12.5 & 6.0 \\\\\n",
       "\t9 & 10 & 16.0 & 6.0 \\\\\n",
       "\t10 & 11 & 2.0 & 8.25 \\\\\n",
       "\t11 & 12 & 14.5 & 8.0 \\\\\n",
       "\t12 & 13 & 5.0 & 9.0 \\\\\n",
       "\t13 & 14 & 8.0 & 9.5 \\\\\n",
       "\t14 & 15 & 1.0 & 11.0 \\\\\n",
       "\t15 & 16 & 3.0 & 10.0 \\\\\n",
       "\t16 & 17 & 12.0 & 10.0 \\\\\n",
       "\t17 & 18 & 15.25 & 10.25 \\\\\n",
       "\t18 & 19 & 5.0 & 12.5 \\\\\n",
       "\t19 & 20 & 10.0 & 11.0 \\\\\n",
       "\t20 & 21 & 7.5 & 12.0 \\\\\n",
       "\t21 & 22 & 15.0 & 12.0 \\\\\n",
       "\t22 & 23 & 11.0 & 13.0 \\\\\n",
       "\t23 & 24 & 13.5 & 13.0 \\\\\n",
       "\t24 & 25 & 2.0 & 14.0 \\\\\n",
       "\t25 & 26 & 15.0 & 15.0 \\\\\n",
       "\t26 & 27 & 1.0 & 15.0 \\\\\n",
       "\t27 & 28 & 3.0 & 15.0 \\\\\n",
       "\t28 & 29 & 6.5 & 15.0 \\\\\n",
       "\t29 & 30 & 9.0 & 15.0 \\\\\n",
       "\t30 & 31 & 4.0 & 16.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m32×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m cluster \u001b[0m\u001b[1m xc       \u001b[0m\u001b[1m yc       \u001b[0m\n",
       "     │\u001b[90m Int64   \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼─────────────────────────────\n",
       "   1 │       2   4.54545   2.90909\n",
       "   2 │       3  11.0       1.0\n",
       "   3 │       4  13.7       2.2\n",
       "   4 │       5  10.0       3.5\n",
       "   5 │       6   6.0       5.0\n",
       "   6 │       7  14.0       5.0\n",
       "   7 │       8   5.0       6.0\n",
       "   8 │       9  12.5       6.0\n",
       "   9 │      10  16.0       6.0\n",
       "  10 │      11   2.0       8.25\n",
       "  11 │      12  14.5       8.0\n",
       "  ⋮  │    ⋮        ⋮         ⋮\n",
       "  23 │      24  13.5      13.0\n",
       "  24 │      25   2.0      14.0\n",
       "  25 │      26  15.0      15.0\n",
       "  26 │      27   1.0      15.0\n",
       "  27 │      28   3.0      15.0\n",
       "  28 │      29   6.5      15.0\n",
       "  29 │      30   9.0      15.0\n",
       "  30 │      31   4.0      16.0\n",
       "  31 │      32   8.0      16.0\n",
       "  32 │      33  11.0      16.0\n",
       "\u001b[36m                    11 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " centres=DataFrame()\n",
    "        clusid=sort(unique(clust))\n",
    "        for j in 2:(length(clusid))\n",
    "            inds=findall(clust .==clusid[j])\n",
    "            xc=mean([inds[x][1] for x in 1:length(inds)])\n",
    "            yc=mean([inds[x][2] for x in 1:length(inds)])\n",
    "            append!(centres,DataFrame(cluster=j,xc=xc,yc=yc))\n",
    "        end\n",
    "\n",
    "centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×32 Matrix{Float64}:\n",
       "  0.0       6.73096   9.18197   5.48646  …  13.1023   13.539    14.5957\n",
       "  6.73096   0.0       2.95466   2.69258     16.5529   15.2971   15.0\n",
       "  9.18197   2.95466   0.0       3.92173     16.868    14.9308   14.0616\n",
       "  5.48646   2.69258   3.92173   0.0         13.8654   12.659    12.5399\n",
       "  2.54708   6.40312   8.19329   4.272       11.1803   11.1803   12.083\n",
       "  9.68299   5.0       2.81603   4.272    …  14.8661   12.53     11.4018\n",
       "  3.12415   7.81025   9.49368   5.59017     10.0499   10.4403   11.6619\n",
       "  8.53396   5.22015   3.98497   3.53553     13.1244   10.9659   10.1119\n",
       " 11.8642    7.07107   4.44185   6.5         15.6205   12.8062   11.1803\n",
       "  5.91647  11.5569   13.1717    9.3039       8.00391   9.80115  11.877\n",
       " 11.1808    7.82624   5.85491   6.36396  …  13.2004   10.3078    8.73212\n",
       "  6.10785  10.0      11.0422    7.43303      7.07107   7.61577   9.21954\n",
       "  7.44137   9.01388   9.26175   6.32456      7.63217   6.5       7.15891\n",
       "  ⋮                                      ⋱             ⋮        \n",
       " 13.8543   11.7047    9.88585   9.86154  …  11.7047    8.06226   5.65685\n",
       " 11.9786   12.0      11.1324    9.55249      7.61577   4.24264   3.0\n",
       " 13.4911   12.2577   10.8019   10.1242       9.96243   6.26498   3.90512\n",
       " 11.3793   15.8114   16.6172   13.2004       2.82843   6.32456   9.21954\n",
       " 15.984    14.5602   12.8658   12.5399      11.0454    7.07107   4.12311\n",
       " 12.6      17.2047   18.0314   14.6031   …   3.16228   7.07107  10.0499\n",
       " 12.1893   16.1245   16.6832   13.4629       1.41421   5.09902   8.06226\n",
       " 12.2479   14.7054   14.686    12.0208       2.69258   1.80278   4.60977\n",
       " 12.8854   14.1421   13.6356   11.5434       5.09902   1.41421   2.23607\n",
       " 13.1023   16.5529   16.868    13.8654       0.0       4.0       7.0\n",
       " 13.539    15.2971   14.9308   12.659    …   4.0       0.0       3.0\n",
       " 14.5957   15.0      14.0616   12.5399       7.0       3.0       0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise(Euclidean(),[centres.xc centres.yc]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise(Euclidean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function perc_up2(dat::DataFrame,Lx::Int64,Ly::Int64)\n",
    "    \n",
    "    d=divisors(Lx,Ly)\n",
    "    \n",
    "    a=DataFrame(vec(collect(Iterators.product(1:Lx,1:Ly))))\n",
    "    \n",
    "    select!(a,\"1\"=>\"x\",\"2\"=>\"y\")\n",
    "    \n",
    "    dat=outerjoin(dat,a, on= [:x=>:x,:y=>:y],order=:right)\n",
    "    \n",
    "    replace!(dat.pres,missing=>0)\n",
    "    \n",
    "    result=DataFrame()\n",
    "    \n",
    "    for i in d\n",
    "        \n",
    "        cutx=ceil.(Int64,collect((1:Lx) ./ i))\n",
    "        cuty=ceil.(Int64,collect((1:Ly) ./ i))\n",
    "        \n",
    "        dat1=deepcopy(dat)\n",
    "        \n",
    "        dat1[!,:x1] =cutx[dat1.x]\n",
    "        dat1[!,:y1] = cuty[dat1.y]\n",
    "        \n",
    "        dat1=combine(groupby(dat1,[:x1,:y1]),:pres=>sum)\n",
    "        \n",
    "        mat1=unstack(dat1,:y1,:x1,:pres_sum)\n",
    "        \n",
    "        mat1=Matrix{Int64}(select(mat1,Not(:y1)))\n",
    "        \n",
    "        clust=zeros(Int64,size(mat1)[1],size(mat1)[2])\n",
    "        \n",
    "        largest=0\n",
    "        \n",
    "        lbl=collect(0:length(clust))\n",
    "        \n",
    "        rw=size(mat1)[1]\n",
    "        cl=size(mat1)[2]\n",
    "        \n",
    "        for i2 in 1:cl \n",
    "            for i1 in 1:rw\n",
    "                \n",
    "                if mat1[i1,i2] > 0\n",
    "                    \n",
    "                    left= (i2-1)==0 ? 0 : clust[i1,i2-1]\n",
    "                    above= (i1-1)==0 ? 0 : clust[i1-1,i2]\n",
    "                    \n",
    "                    if (left==0) && (above==0)\n",
    "                        \n",
    "                        largest+=1\n",
    "                        clust[i1,i2]=largest\n",
    "                        lbl[(rw*(i2-1))+i1]=largest\n",
    "                        \n",
    "                    else\n",
    "                        \n",
    "                        if (left!=0) && (above==0)\n",
    "                            \n",
    "                            clust[i1,i2]=clust[i1,i2-1]\n",
    "                            lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-2))+i1]\n",
    "                            \n",
    "                        else\n",
    "                            \n",
    "                            if (left==0) && (above!=0)\n",
    "                                \n",
    "                                clust[i1,i2]=clust[i1-1,i2]\n",
    "                                lbl[(rw*(i2-1))+i1]=lbl[(rw*(i2-1))+i1-1]\n",
    "                                \n",
    "                            else\n",
    "                                \n",
    "                                newlab=min(left,above)\n",
    "                                lbl[findall(x-> x==left || x==above, lbl)] .=newlab\n",
    "                                clust[i1,i2]=newlab\n",
    "                                clust[findall(x-> x==max(left,above), clust)].=newlab\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #Get the pairwise smallest distances between clusters\n",
    "        centres=DataFrame()\n",
    "        clusid=sort(unique(clust))\n",
    "        for j in 2:(length(clusid))\n",
    "            inds=findall(clust .==clusid[j])\n",
    "            xc=mean([inds[x][1] for x in 1:length(ids)])\n",
    "            yc=mean([inds[x][2] for x in 1:length(ids)])\n",
    "            append!(centres,DataFrame(cluster=j,xc=xc,yc=yc))\n",
    "        end\n",
    "            \n",
    "            \n",
    "        \n",
    "        res=DataFrame(pres=reshape(mat1,length(mat1)),cluster=reshape(clust,length(clust)))\n",
    "        res=combine(groupby(res,:cluster),:pres=>sum)\n",
    "        res=res[res.cluster .!=0,:]\n",
    "\n",
    "        freq=combine(groupby(res,:pres_sum),:pres_sum=>length)\n",
    "\n",
    "        append!(result,DataFrame(d_cutoff=i,cluster=freq.pres_sum,freq=freq.pres_sum_length)) \n",
    "        \n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "#Get the f and cm metrics for the actual datasets\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\",\n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "files=readdir(\"D://Project files//percolation//simdat//bci_spdat\")\n",
    "\n",
    "clusdat=DataFrame()\n",
    "\n",
    "for i in 1:length(files)\n",
    "\n",
    "    dat=CSV.read(string(\"D://Project files//percolation//simdat//bci_spdat//\",files[i]), DataFrame)\n",
    "    \n",
    "    sp1=dat.sp[1]\n",
    "    \n",
    "    pop=spdata[2][findall(spdata[1].==dat.sp[1])]\n",
    "\n",
    "    inds=reduce(vcat,[x .+ collect(0:((pop*8)[1])-1) for x in (1:(pop*40)[1]:nrow(dat))])\n",
    "\n",
    "    #dat_real=dat[inds,:]\n",
    "    \n",
    "    dat=dat[Not(inds),:]\n",
    "    \n",
    "    #pars1=unique(dat_real[:,[:rep,:comp_dist,:disp,:k]])\n",
    "    pars=unique(dat[:,[:rep,:comp_dist,:disp,:k]])\n",
    "        \n",
    "    for j in 1:size(pars)[1]\n",
    "        \n",
    "        rep1=pars.rep[j]\n",
    "        comp_dist1=pars.comp_dist[j]\n",
    "        disp1=pars.disp[j]\n",
    "        k1=pars.k[j]\n",
    "\n",
    "        dat1=dat[dat.rep .==rep1 .&& dat.comp_dist .==comp_dist1 .&& dat.disp .==disp1 .&& dat.k .==k1,[:x,:y,:pres]]\n",
    "        \n",
    "        res=perc_up(dat1,Lx,Ly)\n",
    "            \n",
    "        append!(clusdat,DataFrame(sp=sp1,rep=rep1,comp_dist=comp_dist1,disp=disp1,\n",
    "                                    k=k1,d_cutoff=res.d_cutoff,cluster=res.cluster,\n",
    "                                    freq=res.freq))\n",
    "            \n",
    "    end\n",
    "end\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"clusdat.csv\",clusdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1=res[res.d_cutoff .==a,:]\n",
    "\n",
    "m=sum(res1.cluster .* res1.freq)\n",
    "\n",
    "bls=[2,5,10,15,20,50]\n",
    "\n",
    "res2=zeros(Float64,6)\n",
    "\n",
    "for i in 1:length(bls)\n",
    "    \n",
    "    res2[i]=weibull2(res1.cluster,res1.freq,i,m)\n",
    "    \n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapedat=DataFrame()\n",
    "\n",
    "a=unique(res.d_cutoff)\n",
    "\n",
    "for j in a\n",
    "    \n",
    "    res1=res[res.d_cutoff .==a,:]\n",
    "\n",
    "    x=reduce(vcat,[fill(res1.cluster[i],res1.freq[i]) for i in 1:size(res1)[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binlength=5\n",
    "\n",
    "max1=271\n",
    "l = length(x)\n",
    "\n",
    "d,r=divrem(max1,binlength)\n",
    "\n",
    "lns=fill(binlength,d)\n",
    "lns=vcat(lns,r)\n",
    "\n",
    "df=DataFrame(bins=reduce(vcat, [fill(i, v) for (i, v) in enumerate(lns)]),freq=0)\n",
    "\n",
    "df.vals = 1 .+ binlength .*(df.bins .- 1)\n",
    "\n",
    "[df.freq[i] += 1 for i in x]\n",
    "\n",
    "df=combine(groupby(df,:vals),:freq=> sum,renamecols=false)\n",
    "\n",
    "df=df[df.freq .>0,:]\n",
    "\n",
    "shape(fit_mle(Weibull,wsample(df.vals,df.freq,100) .+ 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=perc_up(dat1,Lx,Ly)\n",
    "\n",
    "a=DataFrame(vec(collect(Iterators.product(divisors(Lx,Ly),1:sum(dat1.pres)))))\n",
    "\n",
    "select!(a,\"1\"=>\"d_cutoff\",\"2\"=>\"cluster\")\n",
    "\n",
    "res1=outerjoin(res,a, on= [:d_cutoff=>:d_cutoff,:cluster=>:cluster],order=:right)\n",
    "\n",
    "replace!(res1.freq,missing=>0)\n",
    "    \n",
    "res1.freq =identity.(res1.freq)\n",
    "\n",
    "fishdat=DataFrame()\n",
    "wshapedat=DataFrame()\n",
    "clusmax=DataFrame()\n",
    "            \n",
    "dv=divisors(Lx,Ly)\n",
    "            \n",
    "clusmax=combine(groupby(res,:d_cutoff),:cluster=>maximum)\n",
    "    \n",
    "rename!(clusmax,:cluster_maximum => :cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=67\n",
    "\n",
    "dat1=res1[res1.d_cutoff .==dv[i],:]\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibull_fit(dat1.cluster,dat1.freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat.freq = dat.freq ./ sum(dat.freq)\n",
    "\n",
    "dat.freq = log.(.- log.(1 .- dat.freq))\n",
    "\n",
    "dat.cluster=log.(dat.cluster)\n",
    "\n",
    "ols = lm(@formula(freq ~ cluster), dat)\n",
    "\n",
    "coef(ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the inflection points\n",
    "\n",
    "    f_dash=segmented_f(met_res,divisors(Lx,Ly))[1]\n",
    "    f_dash_var=segmented_f(met_res,divisors(Lx,Ly))[2]\n",
    "\n",
    "    cm_dash=segmented_cm(met_res,divisors(Lx,Ly))[1]\n",
    "    cm_dash_var=segmented_cm(met_res,divisors(Lx,Ly))[2] \n",
    "    \n",
    "    return f_dash,f_dash_var,cm_dash,cm_dash_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "#Get the f and cm metrics for the actual datasets\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\",\n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "files=readdir(\"D://Project files//percolation//simdat//bci_spdat\")\n",
    "\n",
    "    \n",
    "    dat=CSV.read(string(\"D://Project files//percolation//simdat//bci_spdat//\",files[1]), DataFrame)\n",
    "    \n",
    "    sp1=dat.sp[1]\n",
    "    \n",
    "    pop=spdata[2][findall(spdata[1].==dat.sp[1])]\n",
    "\n",
    "    inds=reduce(vcat,[x .+ collect(0:((pop*8)[1])-1) for x in (1:(pop*40)[1]:nrow(dat))])\n",
    "\n",
    "    #dat_real=dat[inds,:]\n",
    "    \n",
    "    dat=dat[Not(inds),:]\n",
    "    \n",
    "    #pars1=unique(dat_real[:,[:rep,:comp_dist,:disp,:k]])\n",
    "    pars=unique(dat[:,[:rep,:comp_dist,:disp,:k]])\n",
    "    \n",
    "    resdat=DataFrame()\n",
    "\n",
    "#for i in 1:size(pars)[1]\n",
    "    \n",
    "    i=2\n",
    "        \n",
    "        rep1=pars.rep[i]\n",
    "        comp_dist1=pars.comp_dist[i]\n",
    "        disp1=pars.disp[i]\n",
    "        k1=pars.k[i]\n",
    "\n",
    "        dat1=dat[dat.rep .==rep1 .&& dat.comp_dist .==comp_dist1 .&& dat.disp .==disp1 .&& dat.k .==k1,[:x,:y,:pres]]\n",
    "        \n",
    "        res=perc_up(dat1,Lx,Ly)\n",
    "        \n",
    "        #append!(resdat,DataFrame(rep=rep1,comp_dist=comp_dist1,disp=disp1,k=k1,d_cutoff=res.d_cutoff,f=res.f,cm=res.cm,wshape=res.wshape))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res=perc_up(dat1,Lx,Ly)\n",
    "\n",
    "dat2=res[res.d_cutoff .==1,:]\n",
    "\n",
    "plot(dat2.cluster,dat2.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3=resdat[1:67,:]\n",
    "\n",
    "plot(dat3.d_cutoff,dat3.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    a=DataFrame(vec(collect(Iterators.product(divisors(Lx,Ly),1:sum(dat1.pres)))))\n",
    "\n",
    "    select!(a,\"1\"=>\"d_cutoff\",\"2\"=>\"cluster\")\n",
    "\n",
    "    res=outerjoin(res,a, on= [:d_cutoff=>:d_cutoff,:cluster=>:cluster],order=:right)\n",
    "\n",
    "    replace!(res.freq,missing=>0)\n",
    "    \n",
    "    res.freq =identity.(res.freq)\n",
    "\n",
    "    dv=divisors(Lx,Ly)\n",
    "    \n",
    "    i=2\n",
    "    \n",
    "    dat=res[res.d_cutoff .==dv[i],:]\n",
    "    \n",
    "    weibull_fit(dat.cluster,dat.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "    \n",
    "    dat=res[res.d_cutoff .==dv[i],:]\n",
    "    \n",
    "    weibull_fit(dat.cluster,dat.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(fit_mle(Weibull,wsample(dat.cluster,dat.freq,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsample(dat.cluster,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a=DataFrame(vec(collect(Iterators.product(divisors(Lx,Ly),1:sum(dat1.pres)))))\n",
    "#select!(a,\"1\"=>\"d_cutoff\",\"2\"=>\"cluster\")\n",
    "\n",
    "#res=outerjoin(res,a, on= [:d_cutoff=>:d_cutoff,:cluster=>:cluster],order=:right)\n",
    "\n",
    "#res.freq=replace(res.freq,missing=>0)\n",
    "res1=res[res.d_cutoff .==1,:]\n",
    "\n",
    "samp=vcat(fill.(res1.cluster, res1.freq)...)\n",
    "\n",
    "shapedat=zeros(Float64,100)\n",
    "\n",
    "for j in 1:100\n",
    "    shapedat[j]=shape(fit_mle(Weibull, samp, alpha0=1, maxiter= 1000, tol= 1e-16))\n",
    "    \n",
    "\n",
    "for i in unique(res.d_cutoff)\n",
    "    \n",
    "    res1=res[res.d_cutoff .==i,:]\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv=divisors(Lx,Ly)\n",
    "fishdat=DataFrame()\n",
    "clusmax=DataFrame()\n",
    "\n",
    "for i in dv\n",
    "\n",
    "dat1=res[res.d_cutoff .==i,:]\n",
    "\n",
    "fishdat=append!(fishdat,DataFrame(d_cutoff=i,f=fish(dat1.cluster,dat1.freq)))\n",
    "\n",
    "dat1=dat1[dat1.freq.>0,:]\n",
    "\n",
    "clusmax=append!(clusmax,DataFrame(d_cutoff=i,cm=maximum(dat1.cluster)))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_res=innerjoin(fishdat,clusmax,on=:d_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse bci sp files\n",
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances, CategoricalArrays\n",
    "\n",
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "#Get the f and cm metrics for the actual datasets\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\",\n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "files=readdir(\"D://Project files//percolation//simdat//bci_spdat\")\n",
    "\n",
    "result=DataFrame()\n",
    "\n",
    "for i in 1:length(files)\n",
    "    \n",
    "    dat=CSV.read(string(\"D://Project files//percolation//simdat//bci_spdat//\",files[i]), DataFrame)\n",
    "    \n",
    "    sp1=dat.sp[1]\n",
    "    \n",
    "    pop=spdata[2][findall(spdata[1].==dat.sp[i])]\n",
    "\n",
    "    inds=reduce(vcat,[x .+ collect(0:((pop*8)[1])-1) for x in (1:(pop*40)[1]:nrow(dat))])\n",
    "\n",
    "    #dat_real=dat[inds,:]\n",
    "    \n",
    "    dat=dat[Not(inds),:]\n",
    "    \n",
    "    #pars1=unique(dat_real[:,[:rep,:comp_dist,:disp,:k]])\n",
    "    pars=unique(dat[:,[:rep,:comp_dist,:disp,:k]])\n",
    "\n",
    "    for i in 1:nrow(pars)\n",
    "\n",
    "        rep1=pars.rep[i]\n",
    "        comp_dist1=pars.comp_dist[i]\n",
    "        disp1=pars.disp[i]\n",
    "        k1=pars.k[i]\n",
    "\n",
    "        dat1=dat[dat.rep .==rep1 .&& dat.comp_dist .==comp_dist1 .&& dat.disp .==disp1 .&& dat.k .==k1,[:x,:y,:pres]]\n",
    "\n",
    "        res=get_f_cm(dat1,Lx,Ly)\n",
    "\n",
    "        append!(result,DataFrame(sp=sp1,rep=rep1,comp_dist=comp_dist1,disp=disp1,k=k1,f=res[1],f_dev=res[2],cm=res[3],cm_dev=res[4]))\n",
    "        \n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps=unique(result.sp)\n",
    "\n",
    "obs=DataFrame()\n",
    "\n",
    "bcidat=CSV.read(\"C://Users//mihir//projects//percolation//rawdat//bci_select.csv\",DataFrame)\n",
    "bcidat=bcidat[:,[:sp,:x,:y,:pres]]\n",
    "\n",
    "for i in sps\n",
    "    \n",
    "    dat=bcidat[bcidat.sp .==i,[:x,:y,:pres]]\n",
    "    \n",
    "    dat.x=ceil.(Int64,dat.x)\n",
    "    dat.y=ceil.(Int64,dat.y)\n",
    "    \n",
    "    res=get_f_cm(dat,Lx,Ly)\n",
    "    \n",
    "    append!(obs,DataFrame(sp=i,f_obs=res[1],f_var_obs=res[2],cm_obs=res[3],cm_var_obs=res[4]))\n",
    "end\n",
    "    \n",
    "\n",
    "result=innerjoin(result,obs,on=:sp)\n",
    "\n",
    "CSV.write(\"C://Users//mihir//projects//percolation//results//bci_met_res.csv\",result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc functions\n",
    "\n",
    "function add_breakpoint(data, bp)\n",
    "\tdata[!, \"since_bp\"] = max.(0, data[!, \"d_cutoff\"] .- bp);\n",
    "end\n",
    "\n",
    "function fit_piecewise_f(data, minbp, maxbp)\n",
    "  min_deviance = Inf\n",
    "  best_model = nothing\n",
    "  best_bp = 0\n",
    "  current_model = nothing\n",
    "  \n",
    "  for bp in minbp:maxbp\n",
    "    add_breakpoint(data, bp)\n",
    "    current_model = lm(@formula(f ~ d_cutoff + since_bp), data)\n",
    "    if deviance(current_model) < min_deviance\n",
    "      min_deviance = deviance(current_model)\n",
    "      best_model = current_model\n",
    "      best_bp = bp\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  return best_bp,min_deviance\n",
    "end\n",
    "\n",
    "function segmented_f(dat::DataFrame,d::Vector{Int64})\n",
    "    \n",
    "    min_dev = Inf\n",
    "    best_bp = 0\n",
    "    current1=current2=nothing\n",
    "    \n",
    "    for bp in 3:(length(d)-2)\n",
    "        \n",
    "        current1=lm(@formula(f~d_cutoff),dat[1:bp,:])\n",
    "        current2=lm(@formula(f~d_cutoff),dat[(bp+1):length(d),:])\n",
    "        \n",
    "        if (deviance(current1)+deviance(current2)) < min_dev\n",
    "            \n",
    "            min_dev= deviance(current1)+deviance(current2)\n",
    "            best_bp=bp\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return dat.d_cutoff[best_bp],min_dev\n",
    "    \n",
    "end\n",
    "\n",
    "function segmented_cm(dat::DataFrame,d::Vector{Int64})\n",
    "    \n",
    "    min_dev = Inf\n",
    "    best_bp = 0\n",
    "    current1=current2=nothing\n",
    "    \n",
    "    for bp in 3:(length(d)-2)\n",
    "        \n",
    "        current1=lm(@formula(cm~d_cutoff),dat[1:bp,:])\n",
    "        current2=lm(@formula(cm~d_cutoff),dat[(bp+1):length(d),:])\n",
    "        \n",
    "        if (deviance(current1)+deviance(current2)) < min_dev\n",
    "            \n",
    "            min_dev= deviance(current1)+deviance(current2)\n",
    "            best_bp=bp\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return dat.d_cutoff[best_bp],min_dev\n",
    "    \n",
    "end\n",
    "    \n",
    "    \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation code\n",
    "#Goal:To demonstrate that the f1 and cm1 metrices robustly represent the signatures of different dispersion mechanisms\n",
    "#To do: create an example (seed =1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances, CategoricalArrays\n",
    "\n",
    "#Declare the functions\n",
    "\n",
    "#Kill #ndeath individuals with the prob equal to habitat suitability\n",
    "function kill!(A::Matrix{Int8}, B::Matrix{Float64}, ndeath::Int64)\n",
    "\n",
    "    samp=findall(A.==1)\n",
    "    A[wsample(samp,B[samp],ndeath,replace=false)].=0\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "#Calculate recruitment probability as a function of dispersal kernel and neighborhood crowding effect\n",
    "function recprob(a::CartesianIndex{2},A::Matrix{Int8},disps::Int64,d::Int64,\n",
    "        b::Vector{Float64})\n",
    "\n",
    "    xs=((a[1]-disps):(a[1]+disps))\n",
    "    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "    ys=(a[2]-disps):(a[2]+disps)\n",
    "    ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "    prob=0\n",
    "\n",
    "    if sum(A[xs,ys])>0\n",
    "\n",
    "        parents=findall(A[xs,ys].==1)\n",
    "\n",
    "        for i in 1:length(parents)\n",
    "\n",
    "            prob+=pdf(Normal(0,disps/2),euclidean([a[1],a[2]],[xs[parents[i][1]],ys[parents[i][2]]]))\n",
    "        end\n",
    "\n",
    "        xc=((a[1]-d):(a[1]+d))\n",
    "        xc=xc[0 .<xc .<=Ly]\n",
    "\n",
    "        yc=(a[2]-d):(a[2]+d)\n",
    "        yc=yc[0 .<yc .<=Lx]\n",
    "\n",
    "        prob*=b[sum(A[xc,yc])+1]\n",
    "    end\n",
    "\n",
    "    return prob\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function spawns!(A::Matrix{Int8},disps::Int64,comp_dist::Int64,comp_list::Vector{Float64},nbirth::Int64)\n",
    "\n",
    "    samp2=shuffle(findall(A.==0))\n",
    "\n",
    "    probs=map(x->recprob(x,A,disps,comp_dist,comp_list),samp2)\n",
    "\n",
    "    A[wsample(samp2,probs,nbirth,replace=false)].=1\n",
    "\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function sampsim!(A::Matrix{Int8},B::Matrix{Float64},disps::Int64,comp_dist::Int64, comp_list::Vector{Float64},nbirth::Int64,ndeath::Int64)\n",
    "\n",
    "    for i in 1:100\n",
    "\n",
    "        kill!(A,B,ndeath)\n",
    "        spawns!(A,disps,comp_dist,comp_list,nbirth)\n",
    "\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances, CategoricalArrays\n",
    "\n",
    "#Declare the functions\n",
    "\n",
    "#Kill #ndeath individuals with the prob equal to habitat suitability\n",
    "function kill!(A::Matrix{Int8}, B::Matrix{Float64}, ndeath::Int64)\n",
    "\n",
    "    samp=findall(A.==1)\n",
    "    A[wsample(samp,B[samp],ndeath,replace=false)].=0\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "#Calculate recruitment probability as a function of dispersal kernel and neighborhood crowding effect\n",
    "function recprob(a::CartesianIndex{2},A::Matrix{Int8},disps::Int64,d::Int64,\n",
    "        b::Vector{Float64})\n",
    "\n",
    "    xs=((a[1]-disps):(a[1]+disps))\n",
    "    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "    ys=(a[2]-disps):(a[2]+disps)\n",
    "    ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "    prob=0\n",
    "\n",
    "    if sum(A[xs,ys])>0\n",
    "\n",
    "        parents=findall(A[xs,ys].==1)\n",
    "\n",
    "        for i in 1:length(parents)\n",
    "\n",
    "            prob+=pdf(Normal(0,disps/2),euclidean([a[1],a[2]],[xs[parents[i][1]],ys[parents[i][2]]]))\n",
    "        end\n",
    "\n",
    "        xc=((a[1]-d):(a[1]+d))\n",
    "        xc=xc[0 .<xc .<=Ly]\n",
    "\n",
    "        yc=(a[2]-d):(a[2]+d)\n",
    "        yc=yc[0 .<yc .<=Lx]\n",
    "\n",
    "        prob*=b[sum(A[xc,yc])+1]\n",
    "    end\n",
    "\n",
    "    return prob\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function spawns!(A::Matrix{Int8},disps::Int64,comp_dist::Int64,comp_list::Vector{Float64},nbirth::Int64)\n",
    "\n",
    "    samp2=shuffle(findall(A.==0))\n",
    "\n",
    "    probs=map(x->recprob(x,A,disps,comp_dist,comp_list),samp2)\n",
    "\n",
    "    A[wsample(samp2,probs,nbirth,replace=false)].=1\n",
    "\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function sampsim!(A::Matrix{Int8},B::Matrix{Float64},disps::Int64,comp_dist::Int64, comp_list::Vector{Float64},nbirth::Int64,ndeath::Int64)\n",
    "\n",
    "    for i in 1:80\n",
    "\n",
    "        kill!(A,B,ndeath)\n",
    "        spawns!(A,disps,comp_dist,comp_list,nbirth)\n",
    "\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "#Set up parameters\n",
    "\n",
    "num= Base.parse(Int, ENV[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\",\n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "#Load the demography data\n",
    "demo_data=CSV.read(string(\"/gpfs/home/mumarani/perc.demodata.bci.csv\"),DataFrame)\n",
    "\n",
    "comp_dists=[15,30]\n",
    "ks=[-20,-1,1,20]\n",
    "\n",
    "disps=[spdata[3][num],2,5,10,20]\n",
    "\n",
    "pars=collect(Iterators.product(comp_dists,ks,disps))\n",
    "\n",
    "abun=spdata[2][num]\n",
    "\n",
    "demodat=demo_data[demo_data.sp .== spdata[1][num],:]\n",
    "\n",
    "nbirth=ndeath=abs(ceil(Int64,rand(Normal(demodat[1,3],demodat[1,4]))))\n",
    "\n",
    "\n",
    "result=DataFrame()\n",
    "\n",
    " for i1 in 1:5\n",
    "\n",
    "        landscape=CSV.read(string(\"/gpfs/home/mumarani/landscapes2/\",readdir(\"/gpfs/home/mumarani/landscapes2\")[i1]), DataFrame)\n",
    "        repl=landscape.rep[1]\n",
    "        rangepar=landscape.rangepars[1]\n",
    "        landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "        initial=filter(:pres => x-> x .== 1,landscape)\n",
    "        initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "\n",
    "        init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "        init=Matrix{Int8}(init[:,Not(\"y\")])\n",
    "\n",
    "        habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "        habmat=Matrix{Float64}(habmat[:,Not(\"y\")])\n",
    "\n",
    "        popmat=deepcopy(init)\n",
    "\n",
    "        for i2 in 1:length(pars)\n",
    "\n",
    "            comp_dist=pars[i2][1]\n",
    "            k=pars[i2][2]\n",
    "            disp=pars[i2][3]\n",
    "\n",
    "            maxnb=((2*comp_dist+1)^2)-1\n",
    "            comp_list=map(y-> 1/(1+exp(k*(-y))),1:maxnb)\n",
    "            comp_list=(comp_list .- minimum(comp_list) .+ 0.1)/(maximum(comp_list)-minimum(comp_list) .+ 0.1)\n",
    "\n",
    "            sampsim!(popmat,habmat,disp,comp_dist,comp_list,nbirth,ndeath)\n",
    "\n",
    "            popmat1=DataFrame(popmat,:auto)\n",
    "            rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "            popmat1[:,:y].=1:Ly\n",
    "            popmat1=stack(popmat1,1:Lx)\n",
    "            rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "            popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "            filter!(:pres => x-> x .== 1,popmat1)\n",
    "            popmat1[:,:rep].=repl\n",
    "            popmat1[:,:rangepar].=rangepar\n",
    "            popmat1[:,:disp].=disp\n",
    "            popmat1[:,:k].=k\n",
    "            popmat1[:,:sp].=spdata[1][num]\n",
    "            append!(result,popmat1)\n",
    "        end\n",
    "    end\n",
    "    CSV.write(string(spdata[1][num],\".csv\"),result)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances\n",
    "\n",
    "#Declare the functions\n",
    "\n",
    "#Kill #ndeath individuals with the prob equal to habitat suitability\n",
    "function kill!(A::Matrix{Int8}, B::Matrix{Float64}, ndeath::Int64)\n",
    "\n",
    "    samp=findall(A.==1)\n",
    "    A[wsample(samp,B[samp],ndeath,replace=false)].=0\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "#Calculate recruitment probability as a function of dispersal kernel and neighborhood crowding effect\n",
    "function recprob(a::CartesianIndex{2},A::Matrix{Int8},disps::Int64,d::Int64,\n",
    "        b::Vector{Float64})\n",
    "\n",
    "    xs=((a[1]-disps):(a[1]+disps))\n",
    "    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "    ys=(a[2]-disps):(a[2]+disps)\n",
    "    ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "    prob=0\n",
    "\n",
    "    if sum(A[xs,ys])>0\n",
    "\n",
    "        parents=findall(A[xs,ys].==1)\n",
    "\n",
    "        for i in 1:length(parents)\n",
    "\n",
    "            prob+=pdf(Normal(0,disps/2),euclidean([a[1],a[2]],[xs[parents[i][1]],ys[parents[i][2]]]))\n",
    "        end\n",
    "\n",
    "        xc=((a[1]-d):(a[1]+d))\n",
    "        xc=xc[0 .<xc .<=Ly]\n",
    "\n",
    "        yc=(a[2]-d):(a[2]+d)\n",
    "        yc=yc[0 .<yc .<=Lx]\n",
    "\n",
    "        prob*=b[sum(A[xc,yc])+1]\n",
    "    end\n",
    "\n",
    "    return prob\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function spawns!(A::Matrix{Int8},disps::Int64,comp_dist::Int64, comp_list::Vector{Float64},nbirth::Int64)\n",
    "\n",
    "    samp2=shuffle(findall(A.==0))\n",
    "\n",
    "    probs=map(x->recprob(x,A,disps,comp_dist,comp_list),samp2)\n",
    "\n",
    "    A[wsample(samp2,probs,nbirth,replace=false)].=1\n",
    "\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function sampsim!(A::Matrix{Int8},B::Matrix{Float64},disps::Int64,comp_dist::Int64, comp_list::Vector{Float64},nbirth::Int64,ndeath::Int64)\n",
    "\n",
    "    for i in 1:80\n",
    "\n",
    "        kill!(A,B,ndeath)\n",
    "        spawns!(A,disps,comp_dist,comp_list,nbirth)\n",
    "\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\",\n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "demo_data=CSV.read(\"C:/Users/Mihir/Documents/perc.demodata.bci.csv\",DataFrame)\n",
    "\n",
    "comp_dists=[15,30]\n",
    "ks=[-20,-1,1,20]\n",
    "\n",
    "disps=[spdata[3][1],2,5,10,20]\n",
    "\n",
    "pars=collect(Iterators.product(comp_dists,ks,disps))\n",
    "\n",
    "abun=spdata[2][1]\n",
    "\n",
    "demodat=demo_data[demo_data.sp .== spdata[1][1],:]\n",
    "\n",
    "nbirth=ndeath=abs(ceil(Int64,rand(Normal(demodat[1,3],demodat[1,4]))))\n",
    "\n",
    "landscape=CSV.read(\"C:/Users/Mihir/Documents/landscapes/landscape_201.csv\", DataFrame)\n",
    "        repl=landscape.rep[1]\n",
    "        rangepar=landscape.rangepars[1]\n",
    "        landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "        initial=filter(:pres => x-> x .== 1,landscape)\n",
    "        initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "\n",
    "        init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "        init=Matrix{Int8}(init[:,Not(\"y\")])\n",
    "\n",
    "        habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "        habmat=Matrix{Float64}(habmat[:,Not(\"y\")])\n",
    "\n",
    "        popmat=deepcopy(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2=1 \n",
    "\n",
    "comp_dist=pars[i2][1]\n",
    "            k=pars[i2][2]\n",
    "            disp=pars[i2][3]\n",
    "\n",
    "            maxnb=((2*comp_dist+1)^2)-1\n",
    "            comp_list=map(y-> 1/(1+exp(k*(-y))),1:maxnb)\n",
    "            comp_list=(comp_list .- minimum(comp_list))/(maximum(comp_list)-minimum(comp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation code\n",
    "#Simulate the population dynamics for large number of replicates (for each param combo),\n",
    "#calculate f1 and cm1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances\n",
    "\n",
    "#Declare the functions\n",
    " \n",
    "#Kill #ndeath individuals with the prob equal to habitat suitability \n",
    "function kill!(A::Matrix{Int8}, B::Matrix{Float64}, ndeath::Int64)\n",
    "    \n",
    "    samp=findall(A.==1)\n",
    "    A[wsample(samp,B[samp],ndeath,replace=false)].=0\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "#Calculate recruitment probability as a function of dispersal kernel and neighborhood crowding effect \n",
    "function recprob(a::CartesianIndex{2},A::Matrix{Int8},disps::Int64,d::Int64,method::Int64,\n",
    "        b::Tuple{Vector{Float64}, Vector{Float64}})\n",
    "    \n",
    "    xs=((a[1]-disps):(a[1]+disps))\n",
    "    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "    ys=(a[2]-disps):(a[2]+disps)\n",
    "    ys=ys[0 .<ys .<=Lx]\n",
    "    \n",
    "    prob=0\n",
    "   \n",
    "    if sum(A[xs,ys])>0 \n",
    "        \n",
    "        parents=findall(A[xs,ys].==1)\n",
    "\n",
    "        for i in 1:length(parents)\n",
    "            \n",
    "            prob+=pdf(Normal(0,disps/2),euclidean([a[1],a[2]],[xs[parents[i][1]],ys[parents[i][2]]]))\n",
    "        end\n",
    "\n",
    "        xc=((a[1]-d):(a[1]+d))\n",
    "        xc=xc[0 .<xc .<=Ly]\n",
    "\n",
    "        yc=(a[2]-d):(a[2]+d)\n",
    "        yc=yc[0 .<yc .<=Lx]\n",
    "        \n",
    "        prob*=b[method][sum(A[xc,yc])+1]\n",
    "    end\n",
    "    \n",
    "    return prob\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "function spawns!(A::Matrix{Int8},disps::Int64,comp_dist::Int64,method::Int64,\n",
    "        comp_list::Tuple{Vector{Float64}, Vector{Float64}},nbirth::Int64)  \n",
    "    \n",
    "    samp2=shuffle(findall(A.==0))\n",
    "    \n",
    "    probs=map(x->recprob(x,A,disps,comp_dist,method,comp_list),samp2)\n",
    "    \n",
    "    A[wsample(samp2,probs,nbirth,replace=false)].=1\n",
    "    \n",
    "    return nothing\n",
    "    \n",
    "end\n",
    "    \n",
    "\n",
    "function sampsim!(A::Matrix{Int8},B::Matrix{Float64},disps::Int64,comp_dist::Int64,method::Int64,\n",
    "        comp_list::Tuple{Vector{Float64}, Vector{Float64}},nbirth::Int64,ndeath::Int64) \n",
    "    \n",
    "    for i in 1:100\n",
    "        \n",
    "        kill!(A,B,ndeath)\n",
    "        spawns!(A,disps,comp_dist,method,comp_list,nbirth)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx=1000 \n",
    "Ly=500\n",
    "\n",
    "\n",
    "spdata=([ \"alchco\", \"alsebl\", \"casear\", \"cecrin\", \"cordal\", \"crotbi\", \"jac1co\", \n",
    "        \"luehse\", \"micoar\", \"paligu\", \"termam\", \"zantpr\"],[271,9913,108,1381,223,634,309,\n",
    "        199,652,1326,58,72],[2,4,2,1,7,3,22,9,52,6,84,1])\n",
    "\n",
    "#Load the demography data\n",
    "demo_data=CSV.read(string(\"C:/Users/mihir/Documents/perc.demodata.bci.csv\"),DataFrame)\n",
    "\n",
    "inds=[1,2,3,4,5,101,102,103,104,105,201,202,203,204,205]\n",
    "\n",
    "comp_dists=[15,30]\n",
    "methodrefs=DataFrame(ind=[1, 2], methods=[\"positive\",\"negative\"])\n",
    "pars=collect(Iterators.product([15,30],[1,2]))\n",
    "\n",
    "cd(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\")\n",
    "\n",
    "bigres=DataFrame()\n",
    "\n",
    "for i in 9:length(spdata[1])\n",
    "    \n",
    "    disp=spdata[3][i]\n",
    "    \n",
    "    abun=spdata[2][i]\n",
    "    \n",
    "    demodat=demo_data[demo_data.sp .== spdata[1][i],:]\n",
    "    \n",
    "    nbirth=ndeath=abs(ceil(Int64,rand(Normal(demodat[1,3],demodat[1,4]))))\n",
    "    \n",
    "    result=DataFrame()\n",
    "\n",
    "    for i1 in inds\n",
    "\n",
    "        landscape=CSV.read(string(\"landscape_\",i1,\".csv\"), DataFrame)\n",
    "        repl=landscape.rep[1] \n",
    "        rangepar=landscape.rangepars[1]    \n",
    "        landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "        initial=filter(:pres => x-> x .== 1,landscape)\n",
    "        initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "\n",
    "        init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "        init=Matrix{Int8}(init[:,Not(\"y\")])\n",
    "\n",
    "        habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "        habmat=Matrix{Float64}(habmat[:,Not(\"y\")])\n",
    "\n",
    "        popmat=deepcopy(init)\n",
    "        \n",
    "        for i2 in 1:length(pars)\n",
    "        \n",
    "            comp_dist=pars[i2][2]\n",
    "            method=pars[i2][2]\n",
    "\n",
    "            maxnb=((2*comp_dist+1)^2)-1\n",
    "            neigh=log.(maxnb,1:maxnb)\n",
    "            comp_list=([0.1; 0.1 .+ neigh],[1.0;1.0 .- neigh])\n",
    "\n",
    "            sampsim!(popmat,habmat,disp,comp_dist,method,comp_list,nbirth,ndeath)\n",
    "\n",
    "            popmat1=DataFrame(popmat,:auto)\n",
    "            rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "            popmat1[:,:y].=1:Ly\n",
    "            popmat1=stack(popmat1,1:Lx)\n",
    "            rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "            popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "            filter!(:pres => x-> x .== 1,popmat1)\n",
    "            popmat1[:,:rep].=repl \n",
    "            popmat1[:,:rangepar].=rangepar\n",
    "            popmat1[:,:disp].=disp\n",
    "            popmat1[:,:method].=method\n",
    "            popmat1[:,:sp].=spdata[1][i]\n",
    "            append!(result,popmat1)\n",
    "            append!(bigres,popmat1)\n",
    "        end\n",
    "    end\n",
    "    CSV.write(string(spdata[1][i],\".csv\"),result)\n",
    "end\n",
    "CSV.write(string(\"bci_perc_null\",\".csv\"),result)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?CSV.write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data=CSV.read(string(\"C:/Users/mihir/Documents/perc.demodata.bci.csv\"),DataFrame)\n",
    "demo_data=demo_data[Not(3),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1=1\n",
    "i2=1\n",
    "abun=1000\n",
    "\n",
    "\n",
    "landscape=CSV.read(string(\"landscape_\",i1,\".csv\"), DataFrame)\n",
    "        landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "        initial=filter(:pres => x-> x .== 1,landscape)\n",
    "        initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "\n",
    "        init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "        init=Matrix{Int8}(init[:,Not(\"y\")])\n",
    "\n",
    "        habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "        habmat=Matrix{Float64}(habmat[:,Not(\"y\")])\n",
    "            \n",
    "        comp_dist=pars[i2][2]\n",
    "        method=pars[i2][2]\n",
    "\n",
    "        maxnb=((2*comp_dist+1)^2)-1\n",
    "        neigh=log.(maxnb,1:maxnb)\n",
    "        comp_list=([0.1; 0.1 .+ neigh],[1.0;1.0 .- neigh])\n",
    "  \n",
    "\n",
    "        popmat=deepcopy(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, LinearAlgebra, Distributions, Distances\n",
    "\n",
    "#Declare the functions\n",
    " \n",
    "#Kill #ndeath individuals with the prob equal to habitat suitability \n",
    "function kill!(A::Matrix{Int8}, B::Matrix{Float64}, ndeath::Int64)\n",
    "    \n",
    "    samp=findall(A.==1)\n",
    "    A[wsample(samp,B[samp],ndeath,replace=false)].=0\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "#Calculate recruitment probability as a function of dispersal kernel and neighborhood crowding effect \n",
    "function recprob(a::CartesianIndex{2},A::Matrix{Int8},disps::Int64,d::Int64,method::Int64,\n",
    "        b::Tuple{Vector{Int64}, Vector{Float64}, Vector{Float64}})\n",
    "    \n",
    "    xs=((a[1]-disps):(a[1]+disps))\n",
    "    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "    ys=(a[2]-disps):(a[2]+disps)\n",
    "    ys=ys[0 .<ys .<=Lx]\n",
    "    \n",
    "    prob=0\n",
    "   \n",
    "    if sum(A[xs,ys])>0 \n",
    "        \n",
    "        parents=findall(popmat[xs,ys].==1)\n",
    "\n",
    "        for i in 1:length(parents)\n",
    "            \n",
    "            prob+=pdf(Normal(0,disps/2),euclidean([a[1],a[2]],[xs[parents[i][1]],ys[parents[i][2]]]))\n",
    "        end\n",
    "\n",
    "        xc=((a[1]-d):(a[1]+d))\n",
    "        xc=xc[0 .<xc .<=Ly]\n",
    "\n",
    "        yc=(a[2]-d):(a[2]+d)\n",
    "        yc=yc[0 .<yc .<=Lx]\n",
    "        \n",
    "        prob*=comp_list[method][sum(A[xc,yc])+1]\n",
    "    end\n",
    "    \n",
    "    return prob\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "function spawns!(A::Matrix{Int8},disps::Int64,comp_dist::Int64,method::Int64,\n",
    "        comp_list::Tuple{Vector{Int64}, Vector{Float64}, Vector{Float64}},nbirth::Int64)  \n",
    "    \n",
    "    samp2=shuffle(findall(A.==0))\n",
    "    \n",
    "    probs=map(x->recprob(x,A,disps,comp_dist,method,comp_list),samp2)\n",
    "    \n",
    "    A[wsample(samp2,probs,nbirth,replace=false)].=1\n",
    "    \n",
    "    return nothing\n",
    "    \n",
    "end\n",
    "    \n",
    "\n",
    "function sampsim!(A::Matrix{Int8},B::Matrix{Float64},disps::Int64,comp_dist::Int64,method::Int64,\n",
    "        comp_list::Tuple{Vector{Int64}, Vector{Float64}, Vector{Float64}},nbirth::Int64,ndeath::Int64) \n",
    "    \n",
    "    for i in 1:100\n",
    "        \n",
    "        kill!(A,B,ndeath)\n",
    "        spawns!(A,disps,comp_dist,method,comp_list,nbirth)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return nothing\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using  CSV, DataFrames, Random, LinearAlgebra, Distributions\n",
    "\n",
    "d_cutoffs=[[1,2];collect(5:5:100)]\n",
    "Lx=1000\n",
    "Ly=500\n",
    "\n",
    "files=readdir(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\")\n",
    "finals=files[occursin.(\"final\",files)]\n",
    "initials=files[occursin.(\"ini tial\",files)]\n",
    "landscapes=files[occursin.(\"landscape\",files)]\n",
    "\n",
    "results=DataFrame()\n",
    "\n",
    "for i in 1:length(finals)\n",
    "    \n",
    "    data=CSV.read(string(\"C:/Users/mihir/Documents/landscapes/\",finals[i]),DataFrame)\n",
    "    \n",
    "    param=unique(data[:,[:rep,:rangepar,:disp,:method]])\n",
    "    \n",
    "    for j in 1:nrow(param)\n",
    "        \n",
    "        dat= data[(data.rep .==param[j,1]) .& (data.rangepar .==param[j,2]) .& \n",
    "            (data.disp .==param[j,3]) .& (data.method .==param[j,4]),:]\n",
    "        \n",
    "        for k in d_cutoffs\n",
    "            \n",
    "            dat2=dat\n",
    "            \n",
    "            dat2[:,:x]=map(x -> findlast(x .>= collect(1:k:Lx)), dat2[:,:x])\n",
    "            \n",
    "            dat2[:,:y]=map(x -> findlast(x .>= collect(1:k:Ly)), dat2[:,:y])\n",
    "            \n",
    "            dat1=zeros(Int8,ceil(Int,Ly/k),ceil(Int,Lx/k))\n",
    "            \n",
    "            for k1 in 1:nrow(dat2)\n",
    "                \n",
    "                dat1[dat2[k1,:y],dat2[k1,:x]]=1\n",
    "            end\n",
    "            \n",
    "            clust=zeros(Int,size(dat1))\n",
    "            \n",
    "            largest=0\n",
    "            \n",
    "            lbl=collect(0:length(clust))\n",
    "            \n",
    "            for i1 in 1:size(dat1)[1], i2 in 1:size(dat1)[2]\n",
    "                \n",
    "                if(dat1[i1,i2]>0)\n",
    "                    \n",
    "                    left=i2>1 ? clust[i1,i2-1] : 0\n",
    "                    above=i1>1 ? clust[i1-1,i2] : 0\n",
    "                    \n",
    "                    if(left==0 && above==0)\n",
    "                        \n",
    "                        largest+=1\n",
    "                        clust[i1,i2]=largest\n",
    "                        lbl[(10*(i2-1))+i1]=largest\n",
    "                    \n",
    "                    elseif(left!=0 && above==0)\n",
    "                        \n",
    "                        clust[i1,i2]=clust[i1,i2-1]\n",
    "                        lbl[(10*(i2-1))+i1]=lbl[(10*(i2-2))+i1]\n",
    "                    \n",
    "                    elseif(left==0 && above!=0)\n",
    "                        \n",
    "                        clust[i1,i2]=clust[i1-1,i2]\n",
    "                        lbl[(10*(i2-1))+i1]=lbl[(10*(i2-1))+i1-1]\n",
    "                    \n",
    "                    else\n",
    "                        \n",
    "                        newlab=min(left,above)\n",
    "                        clust[i1,i2]=newlab\n",
    "                        clust[findall(clust.==max(left,above))].=newlab\n",
    "                        lbl[findall(lbl.==max(left,above))].=newlab\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            clus=unique(clust)\n",
    "            clus=clus[clus.>0]\n",
    "            cnts=[count(i->i.==x, clust) for x=clus]\n",
    "            c_size=unique(cnts)\n",
    "            cnts=[count(i->i.==x,cnts) for x=c_size]\n",
    "            ln=length(c_size)\n",
    "            \n",
    "            res=DataFrame(rep=repeat([param[j,1]],ln),rangepar=repeat([param[j,2]],ln),\n",
    "                disp=repeat([param[j,3]],ln),method=repeat([param[j,4]],ln),\n",
    "                d_cutoff=repeat([k],ln),\n",
    "                cluster=c_size,counts=cnts)\n",
    "            \n",
    "            append!(results,res)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using  CSV, DataFrames, Random, LinearAlgebra, Distributions, Plots\n",
    "\n",
    "Lx=1000 \n",
    "Ly=500\n",
    "abun=1000\n",
    "timepoints=10000\n",
    "nbirth=ndeath=convert(Int64,floor(abun*0.1))\n",
    "\n",
    "disp=5\n",
    "methodrefs=DataFrame(ind=[1, 2, 3], methods=[\"neutral\",\"positive\",\"negative\"])\n",
    "pars=collect(Iterators.product(disp,methodrefs[:,:ind]))\n",
    "\n",
    "cd(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\")\n",
    "\n",
    "landscape=CSV.read(string(\"landscape_\",1,\".csv\"), DataFrame)\n",
    "\n",
    "rangepar=landscape.rangepars[1]\n",
    "      \n",
    "landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "initial=filter(:pres => x-> x .== 1,landscape)\n",
    "\n",
    "scatter(initial.x,initial.y)\n",
    "\n",
    "popmat=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "popmat=Matrix(popmat[:,Not(\"y\")])\n",
    "\n",
    "habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "habmat=Matrix(habmat[:,Not(\"y\")])\n",
    "\n",
    "#Threshold for a suitable habitat\n",
    "mid=quantile(landscape[:,:soiltype],0.5)\n",
    "\n",
    "#Define dispersal probability as a function of #neighbors for all three dispersal methods\n",
    "comp_dist=10\n",
    "maxnb=((2*comp_dist+1)^2)-1\n",
    "neigh=log.(maxnb,1:maxnb)\n",
    "comp_list=(fill(1,(length(neigh)+1)),[0.1; 0.1 .+ neigh],[1.0;1.0 .- neigh])  \n",
    "\n",
    "d=Normal(0,disps/2)\n",
    "\n",
    "result=DataFrame(rangepars=Int[],disp=Int[],method=Int[],x=Int[],y=Int[])\n",
    "\n",
    "\n",
    "for p in 1:length(pars)\n",
    "    \n",
    "    disps=pars[p][1]\n",
    "    methods=pars[p][2]\n",
    "\n",
    "    for i in 1:100\n",
    "\n",
    "        samp2=shuffle(findall(popmat.==1))[collect(1:100)]\n",
    "\n",
    "        for j in 1:length(samp2)\n",
    "\n",
    "            x=samp2[j][1]\n",
    "            y=samp2[j][2]\n",
    "\n",
    "            xs=((x-disps):(x+disps))\n",
    "            xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "            ys=(y-disps):(y+disps)\n",
    "            ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "            inds=collect(Iterators.product(xs,ys))\n",
    "\n",
    "            vals=Float64[]            \n",
    "\n",
    "            for k in 1:length(inds)\n",
    "\n",
    "                xss=((inds[k][1]-comp_dist):(inds[k][1]+comp_dist))\n",
    "                xss=xss[0 .<xss .<=Ly]\n",
    "\n",
    "                yss=(inds[k][2]-comp_dist):(inds[k][2]+comp_dist) \n",
    "                yss=yss[0 .<yss .<=Lx]\n",
    "\n",
    "                nb=sum(popmat[xss,yss])+1 \n",
    "\n",
    "                val=pdf(d,sqrt(((x-inds[k][1])^2)+((y-inds[k][2])^2)))*                \n",
    "                    comp_list[methods][nb]*\n",
    "                    (sign(1-popmat[inds[k][1],inds[k][2]])) \n",
    "\n",
    "                push!(vals,val)\n",
    "\n",
    "            end\n",
    "\n",
    "            ind=wsample(collect(1:length(vals)),vals)\n",
    "\n",
    "            popmat[inds[ind][1],inds[ind][2]]=1\n",
    "\n",
    "        end\n",
    "\n",
    "        #Apply habitat filtering to kill off trees in bad habitats\n",
    "        samp=findall(popmat.==1)\n",
    "        dths=length(samp)-abun\n",
    "        mort=habmat[samp]\n",
    "        del=findall(in.(mort,Ref(sort(mort)[1:dths])))\n",
    "        popmat[samp[del]].=0\n",
    "\n",
    "    end\n",
    "\n",
    "    popmat1=DataFrame(popmat,:auto)\n",
    "    rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "    popmat1[:,:y].=1:Ly\n",
    "    popmat1=stack(popmat1,1:Lx)\n",
    "    rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "    popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "    filter!(:pres => x-> x .== 1,popmat1)\n",
    "\n",
    "    append!(result,DataFrame(rangepars=rangepar,disp=disps,method=methods,x=popmat1.x,y=popmat1.y))  \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using  CSV, DataFrames, Random, LinearAlgebra, Distributions, Plots\n",
    "\n",
    "Lx=1000 \n",
    "Ly=500\n",
    "abun=1000\n",
    "timepoints=10000\n",
    "nbirth=ndeath=convert(Int64,floor(abun*0.1))\n",
    "\n",
    "\n",
    "cd(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\")\n",
    "\n",
    "landscape=CSV.read(string(\"landscape_\",1,\".csv\"), DataFrame)\n",
    "\n",
    "#landscape.soiltype.=1\n",
    "\n",
    "rangepar=landscape.rangepars[1]\n",
    "      \n",
    "landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "\n",
    "initial=filter(:pres => x-> x .== 1,landscape)\n",
    "\n",
    "popmat=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "popmat=Matrix(popmat[:,Not(\"y\")])\n",
    "\n",
    "habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "habmat=Matrix{Float64}(habmat[:,Not(\"y\")])\n",
    "\n",
    "#Threshold for a suitable habitat\n",
    "mid=quantile(landscape[:,:soiltype],0.5)\n",
    "\n",
    "#Define dispersal probability as a function of #neighbors for all three dispersal methods\n",
    "comp_dist=10\n",
    "maxnb=((2*comp_dist+1)^2)-1\n",
    "neigh=log.(maxnb,1:maxnb)\n",
    "comp_list=(fill(1,(length(neigh)+1)),[0.1; 0.1 .+ neigh],[1.0;1.0 .- neigh])  \n",
    "\n",
    "d=Normal(0,disps/2)    \n",
    "\n",
    "sum(popmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps=10\n",
    "\n",
    "methods=2\n",
    "\n",
    "for i in 1:100\n",
    "    \n",
    "        samp=findall(popmat.==1)\n",
    "        mort=habmat[samp]\n",
    "        del=wsample(1:length(mort),mort,ndeath)\n",
    "        push!(ds,length(del))\n",
    "        popmat[samp[del]].=0  \n",
    "        \n",
    "       samp2=shuffle(findall(popmat.==1))\n",
    "    \n",
    "        j=1\n",
    "    \n",
    "        while (sum(popmat)<(abun))\n",
    "\n",
    "            x=samp2[j][1]\n",
    "            y=samp2[j][2]\n",
    "\n",
    "            xs=((x-disps):(x+disps))\n",
    "            xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "            ys=(y-disps):(y+disps)\n",
    "            ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "            inds=collect(Iterators.product(xs,ys))\n",
    "\n",
    "            vals=Float64[]            \n",
    "\n",
    "            for k in 1:length(inds)\n",
    "\n",
    "                xss=((inds[k][1]-comp_dist):(inds[k][1]+comp_dist))\n",
    "                xss=xss[0 .<xss .<=Ly]\n",
    "\n",
    "                yss=(inds[k][2]-comp_dist):(inds[k][2]+comp_dist) \n",
    "                yss=yss[0 .<yss .<=Lx]\n",
    "\n",
    "                nb=sum(popmat[xss,yss])+1 \n",
    "\n",
    "                val=pdf(d,sqrt(((x-inds[k][1])^2)+((y-inds[k][2])^2)))*                \n",
    "                    comp_list[methods][nb]*\n",
    "                    (sign(1-popmat[inds[k][1],inds[k][2]])) \n",
    "\n",
    "                push!(vals,val)\n",
    "\n",
    "            end\n",
    "\n",
    "            ind=wsample(1:length(vals),vals)\n",
    "\n",
    "            popmat[inds[ind][1],inds[ind][2]]=1\n",
    "        \n",
    "            j+=1\n",
    "\n",
    "        end\n",
    "        \n",
    "\n",
    "    end\n",
    "\n",
    "popmat1=DataFrame(popmat,:auto)\n",
    "rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "popmat1[:,:y].=1:500\n",
    "popmat1=stack(popmat1,1:1000)\n",
    "rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "filter!(:pres => x-> x .== 1,popmat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(popmat1.x,popmat1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps=10\n",
    "\n",
    "methods=2\n",
    "\n",
    "ds=[]\n",
    "bs=[]\n",
    "\n",
    "for i in 1:20\n",
    "\n",
    "        samp2=shuffle(findall(popmat.==1))[collect(1:nbirth)]\n",
    "    \n",
    "        for j in 1:length(samp2)\n",
    "\n",
    "            x=samp2[j][1]\n",
    "            y=samp2[j][2]\n",
    "\n",
    "            xs=((x-disps):(x+disps))\n",
    "            xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "            ys=(y-disps):(y+disps)\n",
    "            ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "            inds=collect(Iterators.product(xs,ys))\n",
    "\n",
    "            vals=Float64[]            \n",
    "\n",
    "            for k in 1:length(inds)\n",
    "\n",
    "                xss=((inds[k][1]-comp_dist):(inds[k][1]+comp_dist))\n",
    "                xss=xss[0 .<xss .<=Ly]\n",
    "\n",
    "                yss=(inds[k][2]-comp_dist):(inds[k][2]+comp_dist) \n",
    "                yss=yss[0 .<yss .<=Lx]\n",
    "\n",
    "                nb=sum(popmat[xss,yss])+1 \n",
    "\n",
    "                val=pdf(d,sqrt(((x-inds[k][1])^2)+((y-inds[k][2])^2)))*                \n",
    "                    comp_list[methods][nb]*\n",
    "                    (sign(1-popmat[inds[k][1],inds[k][2]])) \n",
    "\n",
    "                push!(vals,val)\n",
    "\n",
    "            end\n",
    "\n",
    "            ind=wsample(1:length(vals),vals)\n",
    "\n",
    "            popmat[inds[ind][1],inds[ind][2]]=1\n",
    "\n",
    "        end\n",
    "        \n",
    "    \n",
    "        samp=findall(popmat.==1)\n",
    "        deaths=sum(popmat)-abun\n",
    "        push!(ds,deaths)\n",
    "        mort=habmat[samp]\n",
    "        del=wsample(1:length(mort),mort,deaths)\n",
    "        popmat[samp[del]].=0  \n",
    "        \n",
    "    end\n",
    "\n",
    "popmat1=DataFrame(popmat,:auto)\n",
    "rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "popmat1[:,:y].=1:500\n",
    "popmat1=stack(popmat1,1:1000)\n",
    "rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "filter!(:pres => x-> x .== 1,popmat1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps=10\n",
    "\n",
    "methods=2\n",
    "\n",
    "ds=[]\n",
    "bs=[]\n",
    "\n",
    "for i in 1:20\n",
    "\n",
    "        samp2=shuffle(findall(popmat.==1))\n",
    "    \n",
    "        j=1\n",
    "    \n",
    "        while (sum(popmat)<(abun+nbirth))\n",
    "\n",
    "            x=samp2[j][1]\n",
    "            y=samp2[j][2]\n",
    "\n",
    "            xs=((x-disps):(x+disps))\n",
    "            xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "            ys=(y-disps):(y+disps)\n",
    "            ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "            inds=collect(Iterators.product(xs,ys))\n",
    "\n",
    "            vals=Float64[]            \n",
    "\n",
    "            for k in 1:length(inds)\n",
    "\n",
    "                xss=((inds[k][1]-comp_dist):(inds[k][1]+comp_dist))\n",
    "                xss=xss[0 .<xss .<=Ly]\n",
    "\n",
    "                yss=(inds[k][2]-comp_dist):(inds[k][2]+comp_dist) \n",
    "                yss=yss[0 .<yss .<=Lx]\n",
    "\n",
    "                nb=sum(popmat[xss,yss])+1 \n",
    "\n",
    "                val=pdf(d,sqrt(((x-inds[k][1])^2)+((y-inds[k][2])^2)))*                \n",
    "                    comp_list[methods][nb]*\n",
    "                    (sign(1-popmat[inds[k][1],inds[k][2]])) \n",
    "\n",
    "                push!(vals,val)\n",
    "\n",
    "            end\n",
    "\n",
    "            ind=wsample(1:length(vals),vals)\n",
    "\n",
    "            popmat[inds[ind][1],inds[ind][2]]=1\n",
    "        \n",
    "            j+=1\n",
    "\n",
    "        end\n",
    "        \n",
    "    \n",
    "        samp=findall(popmat.==1)\n",
    "        deaths=sum(popmat)-abun\n",
    "        push!(ds,deaths)\n",
    "        mort=habmat[samp]\n",
    "        del=wsample(1:length(mort),mort,deaths)\n",
    "        push!(bs,del)\n",
    "        popmat[samp[del]].=0  \n",
    "        \n",
    "        push!(bs,sum(popmat))\n",
    "\n",
    "    end\n",
    "\n",
    "popmat1=DataFrame(popmat,:auto)\n",
    "rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "popmat1[:,:y].=1:500\n",
    "popmat1=stack(popmat1,1:1000)\n",
    "rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "filter!(:pres => x-> x .== 1,popmat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter(popmat1.x,popmat1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distances, StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\\\\landscape_\",1,\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=CSV.read(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\\\\final_1.csv\",DataFrame)\n",
    "dat= data[(data.rep .==1) .& (data.rangepar .==5) .& \n",
    "            (data.disp .==10) .& (data.method .==\"positive\"),:]\n",
    "\n",
    "dat=transpose(Matrix(dat[:,[:x,:y]]))\n",
    "\n",
    "adj=pairwise(Euclidean(),dat)\n",
    "fg=FeaturedGraph(adj)\n",
    "lp=normalized_laplacian(adj)\n",
    "e=eigen(lp).values\n",
    "e=e[e.>=1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using  CSV, DataFrames, Random, LinearAlgebra, Distributions\n",
    "\n",
    "Lx=1000 \n",
    "Ly=500\n",
    "abun=1000\n",
    "timepoints=100\n",
    "nbirth=ndeath=convert(Int64,floor(abun*0.1))\n",
    "    \n",
    "reps=collect(1:200)\n",
    "disp=(2,5,10,15,30)\n",
    "methodrefs=DataFrame(ind=[1, 2, 3], methods=[\"neutral\",\"positive\",\"negative\"])\n",
    "pars=collect(Iterators.product(disp,methodrefs[:,:ind]))\n",
    "\n",
    "pars=pars[1:2]\n",
    "\n",
    "reps=1\n",
    "\n",
    "landscape=CSV.read(string(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes\\\\landscape_\",reps,\".csv\"), DataFrame)\n",
    "\n",
    "    repl=landscape[1,2]\n",
    "    rangepar=landscape[1,3]    \n",
    "\n",
    "    landscape[:,:pres]=shuffle([ones(Int8,abun);zeros(Int8,(nrow(landscape)-abun))])\n",
    "    landscape[:,:rep]=fill(repl,nrow(landscape))\n",
    "    landscape[:,:rangepars]=fill(rangepar,nrow(landscape))\n",
    "\n",
    "    initial=filter(:pres => x-> x .== 1,landscape)\n",
    "    initial=initial[:,[:rep,:rangepars,:x,:y,:pres]]\n",
    "    \n",
    "    CSV.write(string(\"C:\\\\Users\\\\mihir\\\\Documents\\\\landscapes2\\\\initial_\",reps,\".csv\"),initial)\n",
    "\n",
    "    init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "    init=Matrix(init[:,Not(\"y\")])\n",
    "\n",
    "    habmat=unstack(landscape[:,[\"y\",\"x\",\"soiltype\"]],:y,:x,:soiltype)\n",
    "    habmat=Matrix(habmat[:,Not(\"y\")])\n",
    "    \n",
    "    #Threshold for a suitable habitat\n",
    "    mid=quantile(landscape[:,:soiltype],0.5)\n",
    "    \n",
    "    result=DataFrame()\n",
    "    \n",
    "    i1=1\n",
    "        \n",
    "        disps=pars[i1][1]\n",
    "        methods=pars[i1][2]\n",
    "        \n",
    "        #Define dispersal probability as a function of #neighbors for all three dispersal methods\n",
    "        comp_dist=20\n",
    "        maxnb=((2*comp_dist+1)^2)-1\n",
    "        neigh=log.(maxnb,1:maxnb)\n",
    "        comp_list=(fill(1,(length(neigh)+1)),[0.1; 0.1 .+ neigh],[1.0;1.0 .- neigh])    \n",
    "        \n",
    "        d=Normal(0,disps/2)\n",
    "            \n",
    "        popmat=init\n",
    "            \n",
    "        for i in 1:100\n",
    "                \n",
    "                #Apply habitat filtering to kill off trees in bad habitats\n",
    "                samp=findall(popmat.==1)\n",
    "                mort=habmat[samp]\n",
    "                del=findall(in.(mort,Ref(sort(mort)[1:ndeath])))\n",
    "                popmat[samp[del]].=0\n",
    "                \n",
    "                samp2=shuffle(findall(popmat.==1))[1:100]   \n",
    "\n",
    "                for j in 1:length(samp2)\n",
    "\n",
    "                    x=samp2[j][1]\n",
    "                    y=samp2[j][2]\n",
    "\n",
    "                    xs=((x-disps):(x+disps))\n",
    "                    xs=xs[0 .<xs .<=Ly]\n",
    "\n",
    "                    ys=(y-disps):(y+disps)\n",
    "                    ys=ys[0 .<ys .<=Lx]\n",
    "\n",
    "                    inds=collect(Iterators.product(xs,ys))\n",
    "\n",
    "                    vals=Float64[]            \n",
    "\n",
    "                    for k in 1:length(inds)\n",
    "\n",
    "                        xss=((inds[k][1]-comp_dist):(inds[k][1]+comp_dist))\n",
    "                        xss=xss[0 .<xss .<=Ly]\n",
    "\n",
    "                        yss=(inds[k][2]-comp_dist):(inds[k][2]+comp_dist) \n",
    "                        yss=yss[0 .<yss .<=Lx]\n",
    "\n",
    "                        nb=sum(popmat[xss,yss])+1 \n",
    "\n",
    "                        val=pdf(d,sqrt(((x-inds[k][1])^2)+((y-inds[k][2])^2)))*                \n",
    "                            comp_list[methods][nb]*\n",
    "                            (sign(1-popmat[inds[k][1],inds[k][2]])) \n",
    "\n",
    "                        push!(vals,val)\n",
    "\n",
    "                    end\n",
    "                    \n",
    "                    ind=wsample(collect(1:length(vals)),vals)\n",
    "\n",
    "                    popmat[inds[ind][1],inds[ind][2]]=1\n",
    "                end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        popmat1=DataFrame(popmat,:auto)\n",
    "        rename!(x-> strip(string(x), ['x']),popmat1)\n",
    "        popmat1[:,:y].=1:Ly\n",
    "        popmat1=stack(popmat1,1:Lx)\n",
    "        rename!(popmat1,:variable=> :x, :value => :pres)\n",
    "        popmat1[!,:x] = parse.(Int64,popmat1[!,:x])\n",
    "        filter!(:pres => x-> x .== 1,popmat1)\n",
    "        popmat1[:,:rep].=repl\n",
    "        popmat1[:,:rangepar].=rangepar\n",
    "        popmat1[:,:disp].=disps\n",
    "        popmat1[:,:method].=methodrefs[methods,2]        \n",
    "        append!(result,popmat1)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(groupby(result, [:disp,:method]), nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=unstack(landscape[:,[\"y\",\"x\",\"pres\"]],:y,:x,:pres)\n",
    "    init=Matrix(init[:,Not(\"y\")])\n",
    "sum(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
